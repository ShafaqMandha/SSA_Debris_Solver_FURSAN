{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpsYGHaIWazg"
      },
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# Install dependencies (Colab)\n",
        "# ===============================\n",
        "!pip install dwave-ocean-sdk pandas numpy matplotlib scikit-learn\n",
        "\n",
        "# ===============================\n",
        "# Imports\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import partial\n",
        "\n",
        "import dimod\n",
        "from dimod import BinaryQuadraticModel, SimulatedAnnealingSampler, ExactSolver\n",
        "# LeapHybridSampler may require D-Wave credentials and internet\n",
        "try:\n",
        "    from dwave.system import LeapHybridSampler\n",
        "    HAS_LEAP = True\n",
        "except Exception:\n",
        "    HAS_LEAP = False\n",
        "\n",
        "# ===============================\n",
        "# User config\n",
        "# ===============================\n",
        "CDM_PATH = \"/content/2024_S1_cdm_ccsds.csv\"   # <- replace if needed after upload\n",
        "N_TEST = 10                     # number of highest-risk conjunctions to test\n",
        "DV_LEVELS_PER_AXIS = [0.0, 0.01, 0.03, 0.06]  # discretized magnitudes per axis (m/s)\n",
        "AXES = [\"r\", \"t\", \"n\"]\n",
        "MAX_DV_ALLOW = 0.3              # maximum allowable total Δv (m/s) for feasibility\n",
        "PC_REDUCTION_SCALE = 5.0        # parameter controlling how Δv reduces Pc (higher -> faster reduction)\n",
        "\n",
        "# Weights for QUBO objective (linear combination)\n",
        "W_PC = 1000.0    # penalty weight for remaining collision probability\n",
        "W_DV = 50.0      # cost weight for Δv\n",
        "W_PAIR = 5.0     # interaction penalty to avoid conflicting choices (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Utilities: collision model and helpers\n",
        "# ===============================\n",
        "def collision_probability_after(pc0, dv_total, scale=PC_REDUCTION_SCALE):\n",
        "    \"\"\"\n",
        "    Simple exponential model: Pc_after = pc0 * exp(-scale * dv_total)\n",
        "    (tunable scale; validated in prototype)\n",
        "    \"\"\"\n",
        "    return float(pc0) * math.exp(-scale * dv_total)\n",
        "\n",
        "def make_variables_grid(axes=AXES, levels=DV_LEVELS_PER_AXIS):\n",
        "    \"\"\"\n",
        "    Create list of variable names and mapping variable -> dv magnitude.\n",
        "    We encode each axis with one-hot bins (choose exactly one level per axis).\n",
        "    Include level 0.0 as 'no impulse'.\n",
        "    \"\"\"\n",
        "    var_names = []\n",
        "    var_to_dv = {}\n",
        "    for ax in axes:\n",
        "        for i, lvl in enumerate(levels):\n",
        "            name = f\"dv_{ax}_{i}\"\n",
        "            var_names.append(name)\n",
        "            var_to_dv[name] = float(lvl)\n",
        "    return var_names, var_to_dv\n",
        "\n",
        "# Build one-hot constraint penalty for each axis (want exactly one selection per axis).\n",
        "def add_onehot_penalty(bqm, axis_vars, gamma=50.0):\n",
        "    \"\"\"\n",
        "    Add quadratic penalty gamma*(sum(x_i) - 1)^2 to BQM for variables in axis_vars.\n",
        "    Encourages exactly one level selected per axis (including 0).\n",
        "    \"\"\"\n",
        "    # Expand (sum - 1)^2 = sum_i x_i + 2 sum_{i<j} x_i x_j - 2 sum_i x_i + 1\n",
        "    # Implement via linear and quadratic offsets (constant ignored).\n",
        "    for v in axis_vars:\n",
        "        bqm.add_variable(v, gamma * (1 - 2))  # gamma*(1 -2) = -gamma\n",
        "    for i in range(len(axis_vars)):\n",
        "        for j in range(i+1, len(axis_vars)):\n",
        "            bqm.add_quadratic(axis_vars[i], axis_vars[j], 2 * gamma)\n",
        "    # constant gamma * 1 is irrelevant\n"
      ],
      "metadata": {
        "id": "8E6uwZbBWdyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Load CDM and pre-process\n",
        "# ===============================\n",
        "cdm = pd.read_csv(CDM_PATH, dtype=str)  # read as str to be robust, convert needed cols later\n",
        "# ensure numeric conversion for required columns (coerce where necessary)\n",
        "for col in [\"relative_position_r\",\"relative_position_t\",\"relative_position_n\",\n",
        "            \"relative_velocity_r\",\"relative_velocity_t\",\"relative_velocity_n\",\n",
        "            \"collision_probability\"]:\n",
        "    if col in cdm.columns:\n",
        "        cdm[col] = pd.to_numeric(cdm[col], errors=\"coerce\")\n",
        "    else:\n",
        "        # If some columns are missing, create NaN\n",
        "        cdm[col] = np.nan\n",
        "\n",
        "# compute range and speed\n",
        "cdm[\"range_m\"] = np.sqrt((cdm[[\"relative_position_r\",\"relative_position_t\",\"relative_position_n\"]]**2).sum(axis=1))\n",
        "cdm[\"speed_mps\"] = np.sqrt((cdm[[\"relative_velocity_r\",\"relative_velocity_t\",\"relative_velocity_n\"]]**2).sum(axis=1))\n",
        "cdm[\"Pc\"] = cdm[\"collision_probability\"].fillna(0.0)\n",
        "\n",
        "# select top N highest Pc to test\n",
        "cdm_sorted = cdm.sort_values(\"Pc\", ascending=False).head(N_TEST).reset_index(drop=True)\n",
        "print(f\"Selected {len(cdm_sorted)} conjunctions (top by reported Pc).\")\n",
        "cdm_sorted[[\"conjunction_id\",\"Pc\",\"range_m\",\"speed_mps\"]]\n"
      ],
      "metadata": {
        "id": "OPjXh0vcWhDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Build QUBO builder for one conjunction\n",
        "# ===============================\n",
        "var_names, var_to_dv = make_variables_grid(axes=AXES, levels=DV_LEVELS_PER_AXIS)\n",
        "\n",
        "# group per-axis variables for one-hot\n",
        "axis_vars = {}\n",
        "for ax in AXES:\n",
        "    axis_vars[ax] = [v for v in var_names if v.startswith(f\"dv_{ax}_\")]\n",
        "\n",
        "def build_bqm_for_conjunction(pc0, w_pc=W_PC, w_dv=W_DV, w_pair=W_PAIR):\n",
        "    \"\"\"\n",
        "    Build a BinaryQuadraticModel for a single conjunction with initial Pc = pc0.\n",
        "    The decision selects exactly one level per axis (including 0-level), leading to a\n",
        "    combined Δv vector. Objective: minimize Pc_after + w_dv * dv_total.\n",
        "    We encode Pc_after approximately as w_pc * Pc_after(dv_total).\n",
        "    \"\"\"\n",
        "    bqm = BinaryQuadraticModel({}, {}, 0.0, vartype='BINARY')\n",
        "\n",
        "    # Add variables and linear cost for dv magnitude\n",
        "    for v, dv in var_to_dv.items():\n",
        "        # linear term: w_dv * dv  (propellant cost) + a proxy for risk change if this variable chosen alone\n",
        "        # We do not know dv_total in linear alone; we'll approximate Pc contribution via linearized term:\n",
        "        # Approx linearization: approximate marginal reduction ~ w_pc * pc0 * (1 - exp(-scale * dv)) ~ w_pc * pc0 * scale * dv (for small dv)\n",
        "        linear_pc_proxy = w_pc * pc0 * (1 - math.exp(-PC_REDUCTION_SCALE * dv))\n",
        "        linear = w_dv * dv + linear_pc_proxy\n",
        "        bqm.add_variable(v, linear)\n",
        "\n",
        "    # Pairwise terms: quadratic terms needed to capture combined dv_total in Pc_after\n",
        "    # We approximate combined effect: Pc_after = pc0 * exp(-scale * sum(dv_i * x_i))\n",
        "    # Expand the exponential up to second-order for a quadratic approx:\n",
        "    # exp(-s * S) ≈ 1 - s S + (s^2 S^2)/2 -> gives quadratic cross-terms proportional to dv_i*dv_j\n",
        "    s = PC_REDUCTION_SCALE\n",
        "    for i, vi in enumerate(var_names):\n",
        "        for j in range(i+1, len(var_names)):\n",
        "            vj = var_names[j]\n",
        "            dv_i = var_to_dv[vi]\n",
        "            dv_j = var_to_dv[vj]\n",
        "            # coefficient from second-order term: w_pc * pc0 * (s^2 / 2) * dv_i * dv_j\n",
        "            coef = w_pc * pc0 * ( (s**2) / 2.0 ) * (dv_i * dv_j)\n",
        "            # add quadratic positive coef (since second-order increases objective reduction, but we are minimizing\n",
        "            # so include it with negative sign to reward combined dv)\n",
        "            bqm.add_quadratic(vi, vj, -coef)  # negative -> choosing both reduces the objective\n",
        "    # One-hot penalties: enforce one level per axis\n",
        "    # Use gamma roughly comparable to scale of linear terms\n",
        "    gamma = max(10.0, w_dv * max(var_to_dv.values()) * 10.0)\n",
        "    for ax, vlist in axis_vars.items():\n",
        "        # Add penalty gamma*(sum - 1)^2 -> implemented via linear & quadratic contributions\n",
        "        # Use method defined earlier\n",
        "        for v in vlist:\n",
        "            bqm.add_variable(v, bqm.linear.get(v,0.0) + gamma * (1 - 2))  # -gamma added\n",
        "        for i in range(len(vlist)):\n",
        "            for j in range(i+1, len(vlist)):\n",
        "                bqm.add_quadratic(vlist[i], vlist[j], bqm.quadratic.get((vlist[i], vlist[j]),0.0) + 2 * gamma)\n",
        "\n",
        "    return bqm\n"
      ],
      "metadata": {
        "id": "HMDR4mvLWhkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Solvers to test\n",
        "# ===============================\n",
        "def solve_exact(bqm):\n",
        "    solver = ExactSolver()\n",
        "    t0 = time.perf_counter()\n",
        "    sampleset = solver.sample(bqm)\n",
        "    t1 = time.perf_counter()\n",
        "    return sampleset.first, t1 - t0\n",
        "\n",
        "def solve_simulated_annealing(bqm, num_reads=200):\n",
        "    sampler = SimulatedAnnealingSampler()\n",
        "    t0 = time.perf_counter()\n",
        "    sampleset = sampler.sample(bqm, num_reads=num_reads)\n",
        "    t1 = time.perf_counter()\n",
        "    return sampleset.first, t1 - t0\n",
        "\n",
        "def solve_leap_hybrid(bqm):\n",
        "    if not HAS_LEAP:\n",
        "        return None, None\n",
        "    sampler = LeapHybridSampler()\n",
        "    t0 = time.perf_counter()\n",
        "    sampleset = sampler.sample(bqm)\n",
        "    t1 = time.perf_counter()\n",
        "    return sampleset.first, t1 - t0\n",
        "\n",
        "def solve_greedy(bqm):\n",
        "    # simple greedy baseline: pick for each axis the level with lowest linear bias (ignoring quadratic interactions)\n",
        "    # get axis candidates\n",
        "    chosen = {}\n",
        "    for ax, vlist in axis_vars.items():\n",
        "        best_v, best_score = None, float('inf')\n",
        "        for v in vlist:\n",
        "            score = bqm.linear.get(v, 0.0)\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_v = v\n",
        "        chosen[best_v] = 1\n",
        "    # build a sample dict\n",
        "    sample = {v: 0 for v in var_names}\n",
        "    for v in chosen:\n",
        "        sample[v] = 1\n",
        "    # estimate energy\n",
        "    energy = bqm.energy(sample)\n",
        "    class FakeResult:\n",
        "        def __init__(self, sample, energy):\n",
        "            self.sample = sample\n",
        "            self.energy = energy\n",
        "    t = 0.0\n",
        "    return FakeResult(sample, energy), t\n"
      ],
      "metadata": {
        "id": "7QAJse89WkHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Evaluate solvers on selected conjunctions\n",
        "# ===============================\n",
        "results = []\n",
        "\n",
        "solvers = {\n",
        "    \"Exact\": solve_exact,\n",
        "    \"SimAnneal\": solve_simulated_annealing,\n",
        "    \"LeapHybrid\": solve_leap_hybrid,  # may be None if no credentials\n",
        "    \"Greedy\": solve_greedy\n",
        "}\n",
        "\n",
        "for idx, row in cdm_sorted.iterrows():\n",
        "    conj_id = row.get(\"conjunction_id\", f\"row{idx}\")\n",
        "    pc0 = float(row.get(\"Pc\", 0.0))\n",
        "    # Build BQM\n",
        "    bqm = build_bqm_for_conjunction(pc0)\n",
        "    # solve with available solvers\n",
        "    solver_outcomes = {}\n",
        "    # exact first (if problem size small enough)\n",
        "    for name, fn in solvers.items():\n",
        "        if name == \"LeapHybrid\" and not HAS_LEAP:\n",
        "            solver_outcomes[name] = {\"available\": False}\n",
        "            continue\n",
        "        try:\n",
        "            sol, runtime = fn(bqm)\n",
        "            if sol is None:\n",
        "                solver_outcomes[name] = {\"available\": False}\n",
        "                continue\n",
        "        except Exception as e:\n",
        "            solver_outcomes[name] = {\"available\": False, \"error\": str(e)}\n",
        "            continue\n",
        "\n",
        "        sample = sol.sample\n",
        "        # sample may be a BinaryMappingType or dict; ensure dict-like\n",
        "        if hasattr(sample, \"items\"):\n",
        "            sample_dict = dict(sample)\n",
        "        else:\n",
        "            # some API return attribute sample\n",
        "            sample_dict = dict(sample)\n",
        "\n",
        "        # compute chosen dv_total\n",
        "        dv_total = sum(var_to_dv[v] * int(sample_dict.get(v,0)) for v in var_names)\n",
        "        # compute Pc after using model\n",
        "        pc_after = collision_probability_after(pc0, dv_total)\n",
        "        # feasibility\n",
        "        feasible = dv_total <= MAX_DV_ALLOW\n",
        "        # energy / objective reported by solver\n",
        "        energy = float(sol.energy) if hasattr(sol, \"energy\") else bqm.energy(sample_dict)\n",
        "        # store\n",
        "        solver_outcomes[name] = {\n",
        "            \"available\": True,\n",
        "            \"sample\": sample_dict,\n",
        "            \"dv_total\": dv_total,\n",
        "            \"pc_after\": pc_after,\n",
        "            \"runtime_s\": runtime,\n",
        "            \"energy\": energy,\n",
        "            \"feasible\": feasible\n",
        "        }\n",
        "\n",
        "    # compute optimal from Exact if available to measure optimality gap\n",
        "    exact = solver_outcomes.get(\"Exact\", {})\n",
        "    if exact.get(\"available\"):\n",
        "        exact_energy = exact[\"energy\"]\n",
        "    else:\n",
        "        exact_energy = None\n",
        "\n",
        "    # collect a line per conjunction\n",
        "    results.append({\n",
        "        \"conjunction_id\": conj_id,\n",
        "        \"Pc0\": pc0,\n",
        "        \"exact_energy\": exact_energy,\n",
        "        \"solver_outcomes\": solver_outcomes\n",
        "    })\n",
        "\n",
        "# Summarize table for easy viewing\n",
        "rows_summary = []\n",
        "for r in results:\n",
        "    cid = r[\"conjunction_id\"]\n",
        "    pc0 = r[\"Pc0\"]\n",
        "    for solver_name, out in r[\"solver_outcomes\"].items():\n",
        "        if not out.get(\"available\"):\n",
        "            rows_summary.append({\n",
        "                \"conjunction_id\": cid,\n",
        "                \"solver\": solver_name,\n",
        "                \"available\": False\n",
        "            })\n",
        "        else:\n",
        "            rows_summary.append({\n",
        "                \"conjunction_id\": cid,\n",
        "                \"solver\": solver_name,\n",
        "                \"available\": True,\n",
        "                \"Pc0\": pc0,\n",
        "                \"Pc_after\": out[\"pc_after\"],\n",
        "                \"dv_total\": out[\"dv_total\"],\n",
        "                \"energy\": out[\"energy\"],\n",
        "                \"runtime_s\": out[\"runtime_s\"],\n",
        "                \"feasible\": out[\"feasible\"]\n",
        "            })\n",
        "\n",
        "summary_df = pd.DataFrame(rows_summary)\n",
        "summary_df\n"
      ],
      "metadata": {
        "id": "28n4bW5jWn4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Analysis & Metrics\n",
        "# ===============================\n",
        "# Compute improvement metrics per solver: absolute and relative Pc reduction, feasibility rate, avg dv, avg runtime\n",
        "metrics = []\n",
        "for solver_name in summary_df[\"solver\"].unique():\n",
        "    sub = summary_df[ (summary_df[\"solver\"] == solver_name) & (summary_df[\"available\"]==True) ]\n",
        "    if len(sub)==0:\n",
        "        metrics.append({\n",
        "            \"solver\": solver_name,\n",
        "            \"tested\": 0,\n",
        "            \"feasible_rate\": None,\n",
        "            \"mean_dv\": None,\n",
        "            \"mean_runtime_s\": None,\n",
        "            \"mean_pc_reduction\": None,\n",
        "            \"mean_pc_rel_reduction\": None\n",
        "        })\n",
        "        continue\n",
        "    mean_dv = sub[\"dv_total\"].mean()\n",
        "    mean_runtime = sub[\"runtime_s\"].mean()\n",
        "    # absolute reduction\n",
        "    abs_red = (sub[\"Pc0\"] - sub[\"Pc_after\"]).mean()\n",
        "    rel_red = ((sub[\"Pc0\"] - sub[\"Pc_after\"]) / (sub[\"Pc0\"].replace(0, np.nan))).replace([np.inf, -np.inf], np.nan).mean()\n",
        "    feasible_rate = sub[\"feasible\"].mean()\n",
        "    metrics.append({\n",
        "        \"solver\": solver_name,\n",
        "        \"tested\": len(sub),\n",
        "        \"feasible_rate\": float(feasible_rate),\n",
        "        \"mean_dv\": float(mean_dv),\n",
        "        \"mean_runtime_s\": float(mean_runtime),\n",
        "        \"mean_pc_reduction\": float(abs_red),\n",
        "        \"mean_pc_rel_reduction\": float(rel_red if not np.isnan(rel_red) else 0.0)\n",
        "    })\n",
        "metrics_df = pd.DataFrame(metrics).sort_values(\"solver\")\n",
        "metrics_df\n"
      ],
      "metadata": {
        "id": "q9yU_9B8Wsey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Plots: Pc before vs after (example for SimAnneal)\n",
        "# ===============================\n",
        "def plot_solver_comparison(solverA, solverB):\n",
        "    A = summary_df[ (summary_df[\"solver\"]==solverA) & (summary_df[\"available\"]==True) ].set_index(\"conjunction_id\")\n",
        "    B = summary_df[ (summary_df[\"solver\"]==solverB) & (summary_df[\"available\"]==True) ].set_index(\"conjunction_id\")\n",
        "    # inner join on conj id\n",
        "    common = A.join(B, lsuffix=f\"_{solverA}\", rsuffix=f\"_{solverB}\", how=\"inner\")\n",
        "    if common.empty:\n",
        "        print(\"No common conjunctions solved by both solvers.\")\n",
        "        return\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(common[f\"Pc_after_{solverA}\"], common[f\"Pc_after_{solverB}\"])\n",
        "    plt.plot([0, common[[f\"Pc_after_{solverA}\", f\"Pc_after_{solverB}\"]].max().max()],\n",
        "             [0, common[[f\"Pc_after_{solverA}\", f\"Pc_after_{solverB}\"]].max().max()], '--', alpha=0.5)\n",
        "    plt.xlabel(f\"Pc after ({solverA})\")\n",
        "    plt.ylabel(f\"Pc after ({solverB})\")\n",
        "    plt.title(f\"Pc after: {solverA} vs {solverB}\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Example compare SimAnneal vs Greedy\n",
        "plot_solver_comparison(\"SimAnneal\", \"Greedy\")\n"
      ],
      "metadata": {
        "id": "BWFFtVARWu8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_df.to_csv(\"/content/cdm_maneuver_solver_summary.csv\", index=False)\n",
        "metrics_df.to_csv(\"/content/cdm_maneuver_solver_metrics.csv\", index=False)\n",
        "print(\"Saved summary and metrics to /content/\")\n"
      ],
      "metadata": {
        "id": "Vs8hF7AGWxvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}