{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG3-wLLDYowj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import precision_score, recall_score, mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# =========================\n",
        "# 1ï¸âƒ£ Load dataset\n",
        "# =========================\n",
        "df = pd.read_csv('/content/2024_S1_cdm_ccsds.csv')\n",
        "df = df.infer_objects(copy=False)\n",
        "\n",
        "cols = [\n",
        "    'event_id', 'tca', 'creation_date', 'miss_distance', 'relative_speed',\n",
        "    'relative_position_r', 'relative_position_t', 'relative_position_n',\n",
        "    'relative_velocity_r', 'relative_velocity_t', 'relative_velocity_n',\n",
        "    'object1_area_pc', 'object1_area_pc_max', 'object1_mass',\n",
        "    'object2_area_pc', 'object2_area_pc_max', 'object2_mass',\n",
        "    'collision_probability', 'collision_max_probability'\n",
        "]\n",
        "df = df[cols].copy()\n",
        "\n",
        "# =========================\n",
        "# 2ï¸âƒ£ Preprocessing & Feature Engineering\n",
        "# =========================\n",
        "date_cols = ['tca','creation_date']\n",
        "for c in date_cols:\n",
        "    df[c] = pd.to_datetime(df[c], errors='coerce')\n",
        "\n",
        "df['time_to_tca'] = (df['tca'] - df['creation_date']).dt.total_seconds() / (3600*24)\n",
        "df['t_cd_area_over_mass'] = df['object1_area_pc'] / df['object1_mass']\n",
        "df['t_cr_area_over_mass'] = df['object1_area_pc_max'] / df['object1_mass']\n",
        "df['c_cd_area_over_mass'] = df['object2_area_pc'] / df['object2_mass']\n",
        "df['c_cr_area_over_mass'] = df['object2_area_pc_max'] / df['object2_mass']\n",
        "\n",
        "df = df.drop(date_cols, axis=1)\n",
        "\n",
        "X = df.drop(['collision_probability'], axis=1)\n",
        "y = np.log10(df['collision_probability'].clip(lower=1e-15))\n",
        "\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "X = X.dropna(axis=1, how='all')\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(scaler.fit_transform(X_imputed), columns=X.columns)\n",
        "\n",
        "# =========================\n",
        "# Event-aware 80/20 split\n",
        "# =========================\n",
        "unique_events = df['event_id'].dropna().unique()\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(unique_events)\n",
        "n = len(unique_events)\n",
        "train_e = unique_events[:int(0.8*n)]\n",
        "test_e  = unique_events[int(0.8*n):]\n",
        "\n",
        "def split_by_event(X, y, event_series, train_e, test_e):\n",
        "    X_train = X[event_series.isin(train_e)]\n",
        "    y_train = y[event_series.isin(train_e)]\n",
        "    X_test  = X[event_series.isin(test_e)]\n",
        "    y_test  = y[event_series.isin(test_e)]\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_by_event(\n",
        "    X_scaled, y, df['event_id'], train_e, test_e\n",
        ")\n",
        "\n",
        "risk_thr = -6\n",
        "y_class_train = (y_train >= risk_thr).astype(int)\n",
        "y_class_test  = (y_test >= risk_thr).astype(int)\n",
        "\n",
        "# =========================\n",
        "# CatBoost Regression\n",
        "# =========================\n",
        "cat_params = {\n",
        "    'iterations': 1500,\n",
        "    'learning_rate': 0.03,\n",
        "    'depth': 8,\n",
        "    'l2_leaf_reg': 3,\n",
        "    'random_seed': 42,\n",
        "    'loss_function': 'RMSE',\n",
        "    'verbose': 0,\n",
        "}\n",
        "reg_model = CatBoostRegressor(**cat_params)\n",
        "reg_model.fit(X_train, y_train)\n",
        "y_pred_reg = reg_model.predict(X_test)\n",
        "\n",
        "epsilon = 0.001\n",
        "y_pred_reg_clipped = y_pred_reg.copy()\n",
        "y_pred_reg_clipped[y_pred_reg_clipped < risk_thr] = risk_thr - epsilon\n",
        "\n",
        "# =========================\n",
        "# 5XGBoost Classification\n",
        "# =========================\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "clf_model = GridSearchCV(xgb_clf, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=0)\n",
        "clf_model.fit(X_train, y_class_train)\n",
        "y_pred_clf_class = clf_model.predict(X_test)\n",
        "\n",
        "# Convert class predictions to risk values for L metric\n",
        "y_pred_clf_risk = y_pred_clf_class * (risk_thr + epsilon)\n",
        "\n",
        "# =========================\n",
        "# 6Hybrid: Regression + Classification\n",
        "# =========================\n",
        "hybrid_prob = 0.7 * y_pred_reg + 0.3 * clf_model.predict_proba(X_test)[:,1]\n",
        "hybrid_prob_clipped = hybrid_prob.copy()\n",
        "hybrid_prob_clipped[hybrid_prob_clipped < risk_thr] = risk_thr - epsilon\n",
        "hybrid_class = (hybrid_prob_clipped >= risk_thr).astype(int)\n",
        "\n",
        "# =========================\n",
        "# LRP baseline\n",
        "# =========================\n",
        "r_minus2 = np.log10(df.loc[df['event_id'].isin(test_e), 'collision_max_probability'].clip(lower=1e-15))\n",
        "y_LRP = r_minus2.clip(lower=risk_thr - epsilon)\n",
        "\n",
        "# =========================\n",
        "# Metric calculation\n",
        "# =========================\n",
        "def compute_metrics(y_true_log, y_pred_log, threshold=-6, beta=2):\n",
        "    y_true_class = (y_true_log >= threshold).astype(int)\n",
        "    y_pred_class = (y_pred_log >= threshold).astype(int)\n",
        "    p = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
        "    r = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
        "    F2 = (1 + beta**2) * (p * r) / (beta**2 * p + r + 1e-10)\n",
        "    hr_idx = y_true_class == 1\n",
        "    N_star = hr_idx.sum()\n",
        "    N = len(y_true_log)\n",
        "    MSEHR = (N_star / N) * mean_squared_error(y_true_log[hr_idx], y_pred_log[hr_idx]) if N_star > 0 else 0\n",
        "    L = F2 * MSEHR\n",
        "    return F2, MSEHR, L\n",
        "\n",
        "F2_reg, MSEHR_reg, L_reg = compute_metrics(y_test.values, y_pred_reg_clipped)\n",
        "F2_clf, MSEHR_clf, L_clf = compute_metrics(y_test.values, y_pred_clf_risk + risk_thr - epsilon)\n",
        "F2_hybrid, MSEHR_hybrid, L_hybrid = compute_metrics(y_test.values, hybrid_prob_clipped)\n",
        "F2_LRP, MSEHR_LRP, L_LRP = compute_metrics(y_test.values, y_LRP.values)\n",
        "\n",
        "# =========================\n",
        "# 9Standard metrics\n",
        "# =========================\n",
        "rmse_reg = np.sqrt(mean_squared_error(y_test, y_pred_reg))\n",
        "mae_reg = mean_absolute_error(y_test, y_pred_reg)\n",
        "r2_reg = r2_score(y_test, y_pred_reg)\n",
        "\n",
        "acc_clf = accuracy_score(y_class_test, y_pred_clf_class)\n",
        "f1_clf = f1_score(y_class_test, y_pred_clf_class, average='macro')\n",
        "\n",
        "acc_hybrid = accuracy_score(y_class_test, hybrid_class)\n",
        "f1_hybrid = f1_score(y_class_test, hybrid_class, average='macro')\n",
        "\n",
        "# =========================\n",
        "# Combined results table\n",
        "# =========================\n",
        "results_summary = pd.DataFrame({\n",
        "    'Model': [\n",
        "        'CatBoost Regression',\n",
        "        'XGBoost Classifier',\n",
        "        'Hybrid: CatBoost + XGBoost',\n",
        "        'LRP Baseline'\n",
        "    ],\n",
        "    'RMSE': [rmse_reg, None, None, None],\n",
        "    'MAE': [mae_reg, None, None, None],\n",
        "    'R2': [r2_reg, None, None, None],\n",
        "    'Accuracy': [None, acc_clf, acc_hybrid, None],\n",
        "    'F1_macro': [None, f1_clf, f1_hybrid, None],\n",
        "    'F2_score': [F2_reg, F2_clf, F2_hybrid, F2_LRP],\n",
        "    'MSEHR': [MSEHR_reg, MSEHR_clf, MSEHR_hybrid, MSEHR_LRP],\n",
        "    'L_metric': [L_reg, L_clf, L_hybrid, L_LRP]\n",
        "})\n",
        "\n",
        "results_summary = results_summary.sort_values(by='F2_score', ascending=False)\n",
        "\n",
        "# =========================\n",
        "# Visualization\n",
        "# =========================\n",
        "sns.set(style=\"whitegrid\", font_scale=1.2)\n",
        "fig, axes = plt.subplots(2,2, figsize=(15,10))\n",
        "\n",
        "sns.barplot(x='Model', y='RMSE', data=results_summary, ax=axes[0,0], palette='viridis')\n",
        "axes[0,0].set_title('RMSE (Regression)')\n",
        "axes[0,0].set_ylabel('RMSE')\n",
        "\n",
        "sns.barplot(x='Model', y='Accuracy', data=results_summary, ax=axes[0,1], palette='magma')\n",
        "axes[0,1].set_title('Accuracy (Classification)')\n",
        "\n",
        "sns.barplot(x='Model', y='F2_score', data=results_summary, ax=axes[1,0], palette='coolwarm')\n",
        "axes[1,0].set_title('F2 Score')\n",
        "\n",
        "sns.barplot(x='Model', y='L_metric', data=results_summary, ax=axes[1,1], palette='cividis')\n",
        "axes[1,1].set_title('L Metric')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nðŸ”¹ Final Combined Results Summary:\")\n",
        "print(results_summary)\n",
        "print(\"\\nBest XGBoost Parameters:\", clf_model.best_params_)\n"
      ]
    }
  ]
}